{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKhhaHUvYgoa"
      },
      "source": [
        "# Lab 9 - Named Entity Recognition -- Starting at 18:05\n",
        "\n",
        "In this lab, we will explore models for Named Entity Recognition (as discussed in week 8).\n",
        "\n",
        "NER systems can take many approaches, but the most common is based on sequence classification. That includes older statistical models like HMM, MEMM, and CRF, as well as newer neural models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Note***: Sample code in this labs require specific versions of some packages to be installed, which may cause dependency confilicts with some of the pre-installed packages in Colab. Thus, you may see some error messages indicating the dependency conflicts upon installation. These errors can be ignored and will not affect running of our sample codes since we will not use those conflicted packages."
      ],
      "metadata": {
        "id": "qOp6AElRorI9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xY4scQ1RUve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c22837-be80-407c-ac71-fce292017f11"
      },
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install -U 'scikit-learn<0.24'\n",
        "!pip install urllib3==1.25.11\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit-learn-0.23.2.tar.gz (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting urllib3==1.25.11\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "Successfully installed urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhywiwS-RYcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e474c26e-de24-48bf-cfe1-0575b0b99944"
      },
      "source": [
        "# read IOB tagged NER dataset into a dataframe\n",
        "df = pd.read_csv('https://drive.google.com/uc?id=1UPHg29593FCCNqec6RyYitjfoyY90UWN', encoding = \"ISO-8859-1\")\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS    Tag\n",
              "0  Sentence: 1      Thousands  NNS      O\n",
              "1          NaN             of   IN      O\n",
              "2          NaN  demonstrators  NNS      O\n",
              "3          NaN           have  VBP      O\n",
              "4          NaN        marched  VBN      O\n",
              "5          NaN        through   IN      O\n",
              "6          NaN         London  NNP  B-geo\n",
              "7          NaN             to   TO      O\n",
              "8          NaN        protest   VB      O\n",
              "9          NaN            the   DT      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4387a5ab-d408-4ae9-b85f-07fa2bdde661\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4387a5ab-d408-4ae9-b85f-07fa2bdde661')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4387a5ab-d408-4ae9-b85f-07fa2bdde661 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4387a5ab-d408-4ae9-b85f-07fa2bdde661');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the set of labels in this data:"
      ],
      "metadata": {
        "id": "IeWDFKY_VpCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set(df['Tag'].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nycMuP4Ny4Q",
        "outputId": "1255f141-e41d-45d0-e7e2-6e66b135a06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art',\n",
              " 'B-eve',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-nat',\n",
              " 'B-org',\n",
              " 'B-per',\n",
              " 'B-tim',\n",
              " 'I-art',\n",
              " 'I-eve',\n",
              " 'I-geo',\n",
              " 'I-gpe',\n",
              " 'I-nat',\n",
              " 'I-org',\n",
              " 'I-per',\n",
              " 'I-tim',\n",
              " 'O'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP9s9J-lDKUC"
      },
      "source": [
        "Uou can see the different types of entities: \n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfakfv0CRwAB"
      },
      "source": [
        "## Data Preprocessing\n",
        "First, this dataset has some NaN values that we'll replace with 0 for convenience.\n",
        "\n",
        "We can also count how many unique sentences, words, and tags we have:\n",
        "- 47959 sentences\n",
        "- 35172 unique words / types\n",
        "- 17 tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O7D8niZRu-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66bffda9-a85f-457b-a6ce-e5c6ff7f2b89"
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique() # nunique = the number of unique ones"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 35172, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMRbPJLIR0iH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "69e36b03-dae0-4aeb-be32-84b842011112"
      },
      "source": [
        "df.groupby('Tag').size().reset_index(name='counts')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Tag  counts\n",
              "0   B-art     402\n",
              "1   B-eve     308\n",
              "2   B-geo   37644\n",
              "3   B-gpe   15870\n",
              "4   B-nat     201\n",
              "5   B-org   20143\n",
              "6   B-per   16990\n",
              "7   B-tim   20333\n",
              "8   I-art     297\n",
              "9   I-eve     253\n",
              "10  I-geo    7414\n",
              "11  I-gpe     198\n",
              "12  I-nat      51\n",
              "13  I-org   16784\n",
              "14  I-per   17251\n",
              "15  I-tim    6528\n",
              "16      O  887908"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-340fe13d-49a4-40f5-8fd6-533ae2c433d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tag</th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-art</td>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-eve</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-geo</td>\n",
              "      <td>37644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-gpe</td>\n",
              "      <td>15870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-nat</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B-org</td>\n",
              "      <td>20143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-per</td>\n",
              "      <td>16990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B-tim</td>\n",
              "      <td>20333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I-art</td>\n",
              "      <td>297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I-eve</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I-geo</td>\n",
              "      <td>7414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I-gpe</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I-nat</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I-org</td>\n",
              "      <td>16784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I-per</td>\n",
              "      <td>17251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I-tim</td>\n",
              "      <td>6528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>O</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-340fe13d-49a4-40f5-8fd6-533ae2c433d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-340fe13d-49a4-40f5-8fd6-533ae2c433d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-340fe13d-49a4-40f5-8fd6-533ae2c433d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcu5O3OlEdPA"
      },
      "source": [
        "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. We are going to use a fork of the library because of some issues running the code otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EsvF8uXSgy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cab3f7a-b2e3-4986-d093-0b31e41fd6e4"
      },
      "source": [
        "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Cloning https://github.com/MeMartijn/updated-sklearn-crfsuite.git to /tmp/pip-install-0tt97abn/sklearn-crfsuite_414bc65cc57e4c59bf7803f0ce014d0b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MeMartijn/updated-sklearn-crfsuite.git /tmp/pip-install-0tt97abn/sklearn-crfsuite_414bc65cc57e4c59bf7803f0ce014d0b\n",
            "  Resolved https://github.com/MeMartijn/updated-sklearn-crfsuite.git to commit 675038761b4405f04691a83339d04903790e2b95\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn_crfsuite)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn_crfsuite\n",
            "  Building wheel for sklearn_crfsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn_crfsuite: filename=sklearn_crfsuite-0.3.6-py2.py3-none-any.whl size=10888 sha256=1fb01353c66800a48306a300e2b872a5f552366e3e37e5bfb31d49d6e024d35a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iyyu0j7k/wheels/0b/bc/07/bd75a6f5fa2bf2ea05a5aad8d9ac66d2b5aab93dfd4e1a89de\n",
            "Successfully built sklearn_crfsuite\n",
            "Installing collected packages: python-crfsuite, sklearn_crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn_crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4F991p-IqNS"
      },
      "source": [
        "##Conditional random fields (CRF)\n",
        "\n",
        "This [post](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/) introduce CRF clearly.\n",
        "\n",
        "This [post](https://dax-cdn.cdn.appdomain.cloud/dax-groningen-meaning-bank-modified/1.0.2/data-preview/Part%202%20-%20Named%20Entity%20Recognition.html) may help you in understaind the coding part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Xcf07iR79l"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lambda argument : expression\n",
        "## apply the expression to the argument, and return the result\n",
        "\n",
        "# Add 10 to argument a, and return the result: \n",
        "def addfun(a):\n",
        "    b = a + 10\n",
        "    return b\n",
        "\n",
        "x = lambda a : a + 10\n",
        "print(x(5))\n",
        "print(addfun(5))\n",
        "\n",
        "\n",
        "\n",
        "## this is a function!\n",
        "# lamba function and map()\n",
        "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
        "                                                    s['POS'].values.tolist(), \n",
        "                                                    s['Tag'].values.tolist())]\n",
        "# argument = s; expression = [...]\n",
        "## i.e.,\n",
        "def def_agg_func(s):\n",
        "    # print(type(s)) # <class 'pandas.core.frame.DataFrame'>\n",
        "    # print(s) # each s contains tokens from ONE sentence -- i.e., all items in s share the same sentence id\n",
        "    wpt = []\n",
        "    for w,p,t in zip(s['Word'].values.tolist(),\n",
        "                s['POS'].values.tolist(),\n",
        "                s['Tag'].values.tolist()):\n",
        "        wpt.append((w,p,t))\n",
        "    return wpt\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz63t4oVX3ZI",
        "outputId": "ba15924b-0470-43a3-b292-38b525852e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPELELtSmYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5bd869-7124-4565-d5e4-34185283a032"
      },
      "source": [
        "#Retrieving sentences with their POS and tags.\n",
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
        "                                                           s['POS'].values.tolist(), \n",
        "                                                           s['Tag'].values.tolist())]\n",
        "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
        "        \n",
        "        data_grouped = self.data.groupby('Sentence #')\n",
        "        print(type(data_grouped))\n",
        "        print(data_grouped.head(10))\n",
        "\n",
        "        groupp = data_grouped.apply(def_agg_func)\n",
        "        \n",
        "        print('------------------------------')\n",
        "        print(self.grouped[10])\n",
        "        print(groupp[10]) #<zip object at 0x7fa6c0d57380>\n",
        "        \n",
        "        self.sentences = [s for s in self.grouped]\n",
        "        print(self.sentences[10])\n",
        "        \n",
        "    def get_next(self):\n",
        "        try: \n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s \n",
        "        except:\n",
        "            return None\n",
        "getter = SentenceGetter(df)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
            "              Sentence #           Word  POS Tag\n",
            "0            Sentence: 1      Thousands  NNS   O\n",
            "1            Sentence: 1             of   IN   O\n",
            "2            Sentence: 1  demonstrators  NNS   O\n",
            "3            Sentence: 1           have  VBP   O\n",
            "4            Sentence: 1        marched  VBN   O\n",
            "...                  ...            ...  ...  ..\n",
            "1048570  Sentence: 47959           they  PRP   O\n",
            "1048571  Sentence: 47959      responded  VBD   O\n",
            "1048572  Sentence: 47959             to   TO   O\n",
            "1048573  Sentence: 47959            the   DT   O\n",
            "1048574  Sentence: 47959         attack   NN   O\n",
            "\n",
            "[474199 rows x 4 columns]\n",
            "------------------------------\n",
            "[('In', 'IN', 'O'), ('Beirut', 'NNP', 'B-geo'), (',', ',', 'O'), ('a', 'DT', 'O'), ('string', 'NN', 'O'), ('of', 'IN', 'O'), ('officials', 'NNS', 'O'), ('voiced', 'VBD', 'O'), ('their', 'PRP$', 'O'), ('anger', 'NN', 'O'), (',', ',', 'O'), ('while', 'IN', 'O'), ('at', 'IN', 'O'), ('the', 'DT', 'O'), ('United', 'NNP', 'B-org'), ('Nations', 'NNP', 'I-org'), ('summit', 'NN', 'O'), ('in', 'IN', 'O'), ('New', 'NNP', 'B-geo'), ('York', 'NNP', 'I-geo'), (',', ',', 'O'), ('Prime', 'NNP', 'B-per'), ('Minister', 'NNP', 'O'), ('Fouad', 'NNP', 'B-per'), ('Siniora', 'NNP', 'I-per'), ('said', 'VBD', 'O'), ('the', 'DT', 'O'), ('Lebanese', 'JJ', 'B-gpe'), ('people', 'NNS', 'O'), ('are', 'VBP', 'O'), ('resolute', 'JJ', 'O'), ('in', 'IN', 'O'), ('preventing', 'VBG', 'O'), ('such', 'JJ', 'O'), ('attempts', 'NNS', 'O'), ('from', 'IN', 'O'), ('destroying', 'VBG', 'O'), ('their', 'PRP$', 'O'), ('spirit', 'NN', 'O'), ('.', '.', 'O')]\n",
            "[('In', 'IN', 'O'), ('Beirut', 'NNP', 'B-geo'), (',', ',', 'O'), ('a', 'DT', 'O'), ('string', 'NN', 'O'), ('of', 'IN', 'O'), ('officials', 'NNS', 'O'), ('voiced', 'VBD', 'O'), ('their', 'PRP$', 'O'), ('anger', 'NN', 'O'), (',', ',', 'O'), ('while', 'IN', 'O'), ('at', 'IN', 'O'), ('the', 'DT', 'O'), ('United', 'NNP', 'B-org'), ('Nations', 'NNP', 'I-org'), ('summit', 'NN', 'O'), ('in', 'IN', 'O'), ('New', 'NNP', 'B-geo'), ('York', 'NNP', 'I-geo'), (',', ',', 'O'), ('Prime', 'NNP', 'B-per'), ('Minister', 'NNP', 'O'), ('Fouad', 'NNP', 'B-per'), ('Siniora', 'NNP', 'I-per'), ('said', 'VBD', 'O'), ('the', 'DT', 'O'), ('Lebanese', 'JJ', 'B-gpe'), ('people', 'NNS', 'O'), ('are', 'VBP', 'O'), ('resolute', 'JJ', 'O'), ('in', 'IN', 'O'), ('preventing', 'VBG', 'O'), ('such', 'JJ', 'O'), ('attempts', 'NNS', 'O'), ('from', 'IN', 'O'), ('destroying', 'VBG', 'O'), ('their', 'PRP$', 'O'), ('spirit', 'NN', 'O'), ('.', '.', 'O')]\n",
            "[('In', 'IN', 'O'), ('Beirut', 'NNP', 'B-geo'), (',', ',', 'O'), ('a', 'DT', 'O'), ('string', 'NN', 'O'), ('of', 'IN', 'O'), ('officials', 'NNS', 'O'), ('voiced', 'VBD', 'O'), ('their', 'PRP$', 'O'), ('anger', 'NN', 'O'), (',', ',', 'O'), ('while', 'IN', 'O'), ('at', 'IN', 'O'), ('the', 'DT', 'O'), ('United', 'NNP', 'B-org'), ('Nations', 'NNP', 'I-org'), ('summit', 'NN', 'O'), ('in', 'IN', 'O'), ('New', 'NNP', 'B-geo'), ('York', 'NNP', 'I-geo'), (',', ',', 'O'), ('Prime', 'NNP', 'B-per'), ('Minister', 'NNP', 'O'), ('Fouad', 'NNP', 'B-per'), ('Siniora', 'NNP', 'I-per'), ('said', 'VBD', 'O'), ('the', 'DT', 'O'), ('Lebanese', 'JJ', 'B-gpe'), ('people', 'NNS', 'O'), ('are', 'VBP', 'O'), ('resolute', 'JJ', 'O'), ('in', 'IN', 'O'), ('preventing', 'VBG', 'O'), ('such', 'JJ', 'O'), ('attempts', 'NNS', 'O'), ('from', 'IN', 'O'), ('destroying', 'VBG', 'O'), ('their', 'PRP$', 'O'), ('spirit', 'NN', 'O'), ('.', '.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alfVxIWIFEth"
      },
      "source": [
        "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite format — each sentence should be converted to a list of dicts. The following code was taken from [the official sklearn-crfsuites site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0]) # word-pos-tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOJNvukV5N39",
        "outputId": "eefd80f5-1841-4741-c49b-a08d498fff38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNaQV60cq9FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word2features function will generate additional features on each of our tokens. Because we would like our model to see the adjacent words of each of our tokens as it trains on our data, we structure word2features so that it takes in a full sentence (represented as a list of lists) and the word to generate features on (represented as an index of the supplied sentence). This makes it easier to reference adjacent words as we generate features on them by simply incrementing or decrementing the supplied index.\n",
        "\n",
        "We also create the sentence2features and sentence2labels functions which assist in converting our data at the sentence level. sentence2features generates the feature dicts for each word in a sentence by calling word2features and sentence2labels generates a list of entity labels for each sentence."
      ],
      "metadata": {
        "id": "R9TCyeuRrCL0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbaee897Sqoa"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    \"\"\"\n",
        "    Generates a feature dictionary for a word using the word's position in a sentence\n",
        "    ref: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n",
        "\n",
        "    :param sentence: a sentence stored as a list of lists\n",
        "    :param i: the index of the word in sentence to generate features for\n",
        "    :returns: feature dictionary for the supplied word\n",
        "    \"\"\"\n",
        "    \n",
        "    word = sent[i][0] \n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    \n",
        "    if i > 0: \n",
        "        word1 = sent[i-1][0] # the word in previous timestep\n",
        "        postag1 = sent[i-1][1] # the postag in previous timestep\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True # if i==0, meaning that it is the begining of sentences\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True # if i==len(sent)-1, meaning that it is the end of sentences\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))] # i is the index of the word in its sentence\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent2features(sentences[0])[0] ## features of the first token in the first sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgmHF2LSTGuY",
        "outputId": "c65a8142-732d-495e-a2bb-26d6b3ff4a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bias': 1.0,\n",
              " 'word.lower()': 'thousands',\n",
              " 'word[-3:]': 'nds',\n",
              " 'word[-2:]': 'ds',\n",
              " 'word.isupper()': False,\n",
              " 'word.istitle()': True,\n",
              " 'word.isdigit()': False,\n",
              " 'postag': 'NNS',\n",
              " 'postag[:2]': 'NN',\n",
              " 'BOS': True,\n",
              " '+1:word.lower()': 'of',\n",
              " '+1:word.istitle()': False,\n",
              " '+1:word.isupper()': False,\n",
              " '+1:postag': 'IN',\n",
              " '+1:postag[:2]': 'IN'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9Xu722SzYZ"
      },
      "source": [
        "# data splitting for training and testing\n",
        "\n",
        "X = [sent2features(s) for s in sentences]\n",
        "y = [sent2labels(s) for s in sentences]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will train the model, this could take 3-5 minutes."
      ],
      "metadata": {
        "id": "VjcGanJZfziK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F2kJfNAS1N2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "416a129a-c124-4ec6-afb3-577fb3df9cbf"
      },
      "source": [
        "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs', # Gradient descent using the L-BFGS method\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    max_iterations=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    max_iterations=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxUCHw5FXGt"
      },
      "source": [
        "In assignment 2, we do span-based evaluation. Here, we will do a simple tag-based evluation (ie., is the tag for each word correct?).\n",
        "\n",
        "First, we are going to remove the “O” tag (outside). We do this because it is very common and will dominate our calculation otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSnMwxl4UVPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b2b7b0-7ade-45d8-c857-077923003082"
      },
      "source": [
        "y = df.Tag.values\n",
        "classes = np.unique(y)\n",
        "classes = classes.tolist()\n",
        "print(classes)\n",
        "print('------------')\n",
        "classes.pop()\n",
        "print(classes)\n",
        "# classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O']\n",
            "------------\n",
            "['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9jdSefS4id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea2aabc-6f09-4ee5-94cb-9485c59aac3e"
      },
      "source": [
        "#evaluation\n",
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.45      0.12      0.19       143\n",
            "       B-eve       0.59      0.42      0.49       106\n",
            "       B-geo       0.86      0.91      0.88     12447\n",
            "       B-gpe       0.97      0.94      0.95      5284\n",
            "       B-nat       0.82      0.42      0.56        78\n",
            "       B-org       0.80      0.73      0.76      6615\n",
            "       B-per       0.85      0.82      0.84      5652\n",
            "       B-tim       0.93      0.88      0.90      6856\n",
            "       I-art       0.11      0.03      0.05       105\n",
            "       I-eve       0.38      0.22      0.28        93\n",
            "       I-geo       0.82      0.81      0.81      2520\n",
            "       I-gpe       0.91      0.62      0.74        69\n",
            "       I-nat       1.00      0.43      0.61        23\n",
            "       I-org       0.82      0.80      0.81      5597\n",
            "       I-per       0.85      0.90      0.87      5674\n",
            "       I-tim       0.84      0.74      0.79      2207\n",
            "\n",
            "   micro avg       0.86      0.85      0.85     53469\n",
            "   macro avg       0.75      0.61      0.66     53469\n",
            "weighted avg       0.86      0.85      0.85     53469\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3oWq_PnK8wk"
      },
      "source": [
        "The following shows what our classifier learned. It gives high scores to transitions from the beginning of an entity type (e.g., B-nat) followed by an inside token of the same type (e.g., I-nat), but transitions from the beginning of one entity type to the inside of a different entity type are given negative scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40His-7UKyvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99dddbd3-9034-4838-c7dd-29efe40a4b69"
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top likely transitions:\n",
            "B-nat  -> I-nat   6.934503\n",
            "I-art  -> I-art   6.260215\n",
            "B-art  -> I-art   5.881224\n",
            "I-eve  -> I-eve   5.847777\n",
            "B-eve  -> I-eve   5.586673\n",
            "I-tim  -> I-tim   5.204188\n",
            "I-org  -> I-org   4.782243\n",
            "I-gpe  -> I-gpe   4.699609\n",
            "B-tim  -> I-tim   4.636703\n",
            "B-org  -> I-org   4.282602\n",
            "O      -> O       3.813956\n",
            "B-per  -> I-per   3.698815\n",
            "I-geo  -> I-geo   3.685166\n",
            "B-gpe  -> I-gpe   3.597376\n",
            "B-geo  -> I-geo   3.516476\n",
            "I-per  -> I-per   3.245863\n",
            "I-nat  -> I-nat   2.954009\n",
            "I-geo  -> B-art   1.973397\n",
            "O      -> B-tim   1.748999\n",
            "O      -> B-per   1.620428\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-org  -> I-geo   -4.259782\n",
            "I-org  -> I-per   -4.327937\n",
            "B-geo  -> B-geo   -4.426926\n",
            "B-per  -> I-org   -4.427218\n",
            "B-geo  -> I-gpe   -4.435073\n",
            "B-per  -> I-geo   -4.466408\n",
            "B-tim  -> B-tim   -4.518613\n",
            "B-org  -> I-geo   -4.575173\n",
            "B-geo  -> I-per   -4.793920\n",
            "B-org  -> I-per   -5.036090\n",
            "B-geo  -> I-org   -5.070524\n",
            "B-gpe  -> I-geo   -5.210003\n",
            "B-gpe  -> I-org   -5.287803\n",
            "B-gpe  -> B-gpe   -5.607401\n",
            "O      -> I-per   -5.956129\n",
            "I-per  -> B-per   -5.963596\n",
            "O      -> I-tim   -6.288495\n",
            "O      -> I-org   -6.908351\n",
            "O      -> I-geo   -7.883945\n",
            "B-per  -> B-per   -10.813935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NtszsmkY7Gk"
      },
      "source": [
        "#Bi-LSTM CRF \n",
        "Here, we introduce a pytorch model for NER based on a Bi-LSTM CRF from the Pytorch official documentation: https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLojtV9cz4-0"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0uFNOV8Dcew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d06b93-55cf-4cc4-fba6-7eaed9960802"
      },
      "source": [
        "# Author: Robert Guthrie\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f01052af390>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFTCs6L2ld3y"
      },
      "source": [
        "### Helper functions to make the code more readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR37vgFWlWEL"
      },
      "source": [
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkT9Uf1tlhQo"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awdZ-PIalYS2"
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### nn.Module class"
      ],
      "metadata": {
        "id": "4EsQMQeMVRD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "7LJy4TeNVn1u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_test(nn.Module):\n",
        "    def __init__(self,aa=1):\n",
        "        super(BiLSTM_test, self).__init__()\n",
        "        ## The super call delegates the function call to the parent class, which is nn.Module in your case.\n",
        "        ## This is actually needed to initialize the nn.Module properly. Check [https://docs.python.org/2/library/functions.html#super] for more information.\n",
        "        # nn.Module.__init__(self) ## this line is just another way to initialize \n",
        "        print('__init__aa',aa)\n",
        "    def forward(self,bb):\n",
        "        print('bb',bb)\n",
        "    def forward_test(self,cc):\n",
        "        print('cc',cc)"
      ],
      "metadata": {
        "id": "GnMKgEljuCLo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa = 1\n",
        "bb = 2\n",
        "cc = 3\n",
        "model = BiLSTM_test()\n",
        "forward_output = model(bb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmijvKR6Vfwn",
        "outputId": "a35aeb42-7687-4046-ded6-80b08129cbfe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__aa 1\n",
            "bb 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jHmhCOrmZdf"
      },
      "source": [
        "### Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWl--cyTmbuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7780680f-1e1d-4923-f04c-a51e0175199e"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 5\n",
        "HIDDEN_DIM = 4\n",
        "\n",
        "# Make up some training data\n",
        "training_data = [(\n",
        "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
        "    \"B I I I O O O B I O O\".split()\n",
        "), (\n",
        "    \"georgia tech is a university in georgia\".split(),\n",
        "    \"B I O O O O B\".split()\n",
        ")]\n",
        "\n",
        "word_to_ix = {}\n",
        "for sentence, tags in training_data:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "# Check predictions before training\n",
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
        "    print(model(precheck_sent))\n",
        "\n",
        "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
        "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in training_data:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Check predictions after training\n",
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    print(model(precheck_sent))\n",
        "# We got it!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(2.6907), [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "(tensor(20.4906), [0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"
          ]
        }
      ]
    }
  ]
}