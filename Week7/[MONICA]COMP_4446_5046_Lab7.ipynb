{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siAIwRRGUtWW"
      },
      "source": [
        "# Lab 7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KEY CONTENTS\n",
        "\n",
        "\n",
        "*   Part-Of-Speech Tagging\n",
        "\n",
        "*   Hidden Markov Models (Probability-Based)\n",
        "> It estimates the probability of a tag sequence for a given word sequence\n",
        "\n",
        "    **Hidden States** -- Each observation will have m potential matching hidden states --- e.g., each word will have m potential matching tags to be assigned (the tag state is hidden, as we want to predict those tags).\n",
        "    \n",
        "    **Observation** -- Sequence of Observed Value, e.g., a sentence.\n",
        "\n",
        "    **Model Parameters**\n",
        "\n",
        "    1.   **Transition Probabilities** -- The probability of the specific state transition (i.e., a POS tag is considered as a state; the transition means from ONE hidden state/tag tranfering to another hidden state/tag -- e.g., Noun->Verb)\n",
        "\n",
        "    2.   **Emission Probabilities** -- The relationship between the hidden/tag state and the observation (i.e., the probability of the tag/hidden state TO the observed word/data -> e.g., given the weather/hidden state, predict the type of clothing/observation)\n",
        "\n",
        "\n",
        "\n",
        "*   Viterbi Algorithm*\n"
      ],
      "metadata": {
        "id": "rjtm4fs5yByW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHbXdZ0b7_-W"
      },
      "source": [
        "# POS Tagging\n",
        "POS tagging is the process of labelling a token in a corpus with a part of speech tag, based on the token's context and definition. This task is not straightforward, as a particular word may have a different part of speech based on the context in which the word is used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Yuq_ck8lzM"
      },
      "source": [
        "## Regular Expression Tagger\n",
        "\n",
        "The regular expression tagger assigns tags to tokens on the basis of matching patterns. For instance, we might guess that any word ending in _-ed_ is the past participle of a verb, and any word ending with _'s_ is a possessive noun. We can express these as a list of regular expressions: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_SNkGVsftLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801bda7a-b702-4ae1-aa13-42166ef003a8"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# Downloading required corpus\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import brown\n",
        "\n",
        "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
        "brown_sents = brown.sents(categories='news')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(brown_tagged_sents[77])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YyV6iZyw0vw",
        "outputId": "b018bcce-0b5e-407d-dba3-b1b1f7eca24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Barber', 'NP'), (',', ','), ('who', 'WPS'), ('is', 'BEZ'), ('in', 'IN'), ('his', 'PP$'), ('13th', 'OD'), ('year', 'NN'), ('as', 'CS'), ('a', 'AT'), ('legislator', 'NN'), (',', ','), ('said', 'VBD'), ('there', 'EX'), ('``', '``'), ('are', 'BER'), ('some', 'DTI'), ('members', 'NNS'), ('of', 'IN'), ('our', 'PP$'), ('congressional', 'JJ'), ('delegation', 'NN'), ('in', 'IN'), ('Washington', 'NP'), ('who', 'WPS'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('see', 'VB'), ('it', 'PPO'), ('(', '('), ('the', 'AT'), ('resolution', 'NN'), (')', ')'), ('passed', 'VBN'), (\"''\", \"''\"), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VMB4D7Vfipk"
      },
      "source": [
        " # Define regular expression patterns\n",
        "patterns = [\n",
        "        (r'.*ing$', 'VBG'),               # gerunds\n",
        "        (r'.*ed$', 'VBD'),                # simple past\n",
        "        (r'.*es$', 'VBZ'),                # 3rd singular present\n",
        "        (r'.*ould$', 'MD'),               # modals\n",
        "        (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
        "        (r'.*s$', 'NNS'),                 # plural nouns\n",
        "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
        "        (r'.*', 'NN')                     # nouns (default)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejmC2tSLk3dA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8674cff9-4b35-4bf6-c2e9-244a1b557f69"
      },
      "source": [
        "# Build regular expression tagger using the defined patterns\n",
        "regexp_tagger = nltk.RegexpTagger(patterns)\n",
        "\n",
        "# Print one of the sentences\n",
        "print(brown_sents[77])\n",
        "# Print one of the tagged sentences\n",
        "print(regexp_tagger.tag(brown_sents[77]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Barber', ',', 'who', 'is', 'in', 'his', '13th', 'year', 'as', 'a', 'legislator', ',', 'said', 'there', '``', 'are', 'some', 'members', 'of', 'our', 'congressional', 'delegation', 'in', 'Washington', 'who', 'would', 'like', 'to', 'see', 'it', '(', 'the', 'resolution', ')', 'passed', \"''\", '.']\n",
            "[('Barber', 'NN'), (',', 'NN'), ('who', 'NN'), ('is', 'NNS'), ('in', 'NN'), ('his', 'NNS'), ('13th', 'NN'), ('year', 'NN'), ('as', 'NNS'), ('a', 'NN'), ('legislator', 'NN'), (',', 'NN'), ('said', 'NN'), ('there', 'NN'), ('``', 'NN'), ('are', 'NN'), ('some', 'NN'), ('members', 'NNS'), ('of', 'NN'), ('our', 'NN'), ('congressional', 'NN'), ('delegation', 'NN'), ('in', 'NN'), ('Washington', 'NN'), ('who', 'NN'), ('would', 'MD'), ('like', 'NN'), ('to', 'NN'), ('see', 'NN'), ('it', 'NN'), ('(', 'NN'), ('the', 'NN'), ('resolution', 'NN'), (')', 'NN'), ('passed', 'VBD'), (\"''\", 'NN'), ('.', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8wT_6a7k63S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eec0940-5590-414f-a60c-6f346e8e97e9"
      },
      "source": [
        "# Evaluate the tagger (Calculate the accuracy/performance)\n",
        "regexp_tagger.accuracy(brown_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20326391789486245"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYPlTCtt8s9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e9fd7e-d1f3-42df-8afa-047e066c130a"
      },
      "source": [
        "raw = 'This race is awesome, I want to race too'\n",
        "tokens = word_tokenize(raw)\n",
        "\n",
        "print(regexp_tagger.tag(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'NNS'), ('race', 'NN'), ('is', 'NNS'), ('awesome', 'NN'), (',', 'NN'), ('I', 'NN'), ('want', 'NN'), ('to', 'NN'), ('race', 'NN'), ('too', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GLU4cC8r49g"
      },
      "source": [
        "# Hidden Markov Models \n",
        "\n",
        "A hidden Markov model (HMM) allows us to talk about both observed events (like words that we see in the input) and hidden events (like part-of-speech tags) that we think of as causal factors in our probabilistic model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Uuv3D5YhhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e17ceaf-872d-4fdb-bbad-7bbac440af4d"
      },
      "source": [
        "# Hidden Markov Models in Python\n",
        "# Katrin Erk, https://www.katrinerk.com/, March 2013 updated March 2016\n",
        "#\n",
        "# This HMM addresses the problem of part-of-speech tagging. It estimates\n",
        "# the probability of a tag sequence for a given word sequence as follows:\n",
        "#\n",
        "# Say words = w1....wN\n",
        "# and tags = t1..tN\n",
        "#\n",
        "# then\n",
        "# P(tags | words) is_proportional_to  product P(ti | t{i-1}) P(wi | ti)\n",
        "#\n",
        "# To find the best tag sequence for a given sequence of words,\n",
        "# we want to find the tag sequence that has the maximum P(tags | words)\n",
        "import nltk\n",
        "import sys\n",
        "nltk.download('brown')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import treebank\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO_rZxt1wv2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d078f8ae-507e-4d68-fa42-afe85064a76b"
      },
      "source": [
        "# Estimating P(wi | ti) from corpus data using Maximum Likelihood Estimation (MLE):\n",
        "# P(wi | ti) = count(wi, ti) / count(ti)\n",
        "#\n",
        "# We add an artificial \"start\" tag at the beginning of each sentence, and\n",
        "# We add an artificial \"end\" tag at the end of each sentence.\n",
        "# So we start out with the brown tagged sentences,\n",
        "# add the two artificial tags,\n",
        "# and then make one long list of all the tag/word pairs.\n",
        "\n",
        "brown_tags_words = []\n",
        "brown_tagged_sents = brown.tagged_sents()\n",
        "\n",
        "for sent in brown_tagged_sents:\n",
        "    # sent is a list of word/tag pairs\n",
        "    # add START/START at the beginning\n",
        "    brown_tags_words.append( (\"START\", \"START\") )\n",
        "    # then all the tag/word pairs for the word/tag pairs in the sentence.\n",
        "    # shorten tags to 2 characters each\n",
        "    brown_tags_words.extend([ (tag[:2], word) for (word, tag) in sent ])\n",
        "    # then END/END\n",
        "    brown_tags_words.append( (\"END\", \"END\") )\n",
        "\n",
        "# conditional frequency distribution\n",
        "cfd_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n",
        "# conditional probability distribution\n",
        "cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, nltk.MLEProbDist)\n",
        "##### refers to the emission table --> given the tag, the probability of the word_t is XXX\n",
        "\n",
        "print(\"The probability of an adjective (JJ) being 'new' is\", cpd_tagwords[\"JJ\"].prob(\"new\"))\n",
        "print(\"The probability of a verb (VB) being 'duck' is\", cpd_tagwords[\"VB\"].prob(\"duck\"))\n",
        "\n",
        "# Estimating P(ti | t{i-1}) from corpus data using Maximum Likelihood Estimation (MLE):\n",
        "# P(ti | t{i-1}) = count(t{i-1}, ti) / count(t{i-1})\n",
        "brown_tags = [tag for (tag, word) in brown_tags_words ]\n",
        "\n",
        "# make conditional frequency distribution:\n",
        "# count(t{i-1} ti)\n",
        "cfd_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
        "# make conditional probability distribution, using\n",
        "# maximum likelihood estimate:\n",
        "# P(ti | t{i-1})\n",
        "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)\n",
        "##### refers to the transition table --> given the previous tag, the probability of the tag_i is XXX\n",
        "\n",
        "print(\"If we have just seen 'DT', the probability of 'NN' is\", cpd_tags[\"DT\"].prob(\"NN\"))\n",
        "print( \"If we have just seen 'VB', the probability of 'JJ' is\", cpd_tags[\"VB\"].prob(\"DT\"))\n",
        "print( \"If we have just seen 'VB', the probability of 'NN' is\", cpd_tags[\"VB\"].prob(\"NN\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of an adjective (JJ) being 'new' is 0.01472344917632025\n",
            "The probability of a verb (VB) being 'duck' is 6.042713350943527e-05\n",
            "If we have just seen 'DT', the probability of 'NN' is 0.5057722522030194\n",
            "If we have just seen 'VB', the probability of 'JJ' is 0.016885067592065053\n",
            "If we have just seen 'VB', the probability of 'NN' is 0.10970977711020183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V35OhECloeUl"
      },
      "source": [
        "## Viterbi Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaetc1FSsgLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85601be-9f3f-43a1-b153-0e7237b46cf7"
      },
      "source": [
        "#####\n",
        "# Viterbi:\n",
        "# If we have a word sequence, what is the best tag sequence?\n",
        "#\n",
        "# The method above lets us determine the probability for a single tag sequence.\n",
        "# But in order to find the best tag sequence, we need the probability\n",
        "# for _all_ tag sequence.\n",
        "# What Viterbi gives us is just a good way of computing all those many probabilities\n",
        "# as fast as possible.\n",
        "\n",
        "# what is the list of all tags?\n",
        "distinct_tags = set(brown_tags)\n",
        "\n",
        "sentence = [\"This\", \"race\", \"is\", \"awesome\", \",\", \"I\", \"want\", \"to\", \"race\", \"too\" ]\n",
        "#sentence = [\"I\", \"saw\", \"her\", \"duck\" ]\n",
        "sentlen = len(sentence)\n",
        "\n",
        "# viterbi:\n",
        "# for each step i in 1 .. sentlen,\n",
        "# store a dictionary\n",
        "# that maps each tag X\n",
        "# to the probability of the best tag sequence of length i that ends in X\n",
        "viterbi = [ ]\n",
        "\n",
        "# backpointer:\n",
        "# for each step i in 1..sentlen,\n",
        "# store a dictionary\n",
        "# that maps each tag X\n",
        "# to the previous tag in the best tag sequence of length i that ends in X\n",
        "backpointer = [ ]\n",
        "\n",
        "\n",
        "##### AT The First Timestep --- first word\n",
        "first_viterbi = { }\n",
        "first_backpointer = { }\n",
        "for tag in distinct_tags:\n",
        "    # don't record anything for the START tag\n",
        "    if tag == \"START\": continue\n",
        "    ##### cpd_tags refers to the transition table --> given the previous tag, the probability of the tag_t is XXX\n",
        "    ###### cpd_tags['tag_(t-1)'].prob(tag_t) == P(tag_t|tag_(t-1))\n",
        "    ##### cpd_tagwords refers to the emission table --> given the tag, the probability of the word_t is XXX\n",
        "    ###### cpd_tagwords['tag_t'].prob(word_t) == P(word_t|tag_t)\n",
        "    \n",
        "    first_viterbi[ tag ] = cpd_tags[\"START\"].prob(tag) * cpd_tagwords[tag].prob( sentence[0] )\n",
        "    first_backpointer[ tag ] = \"START\"\n",
        "\n",
        "print(first_viterbi)\n",
        "print(first_backpointer)\n",
        "    \n",
        "viterbi.append(first_viterbi)\n",
        "backpointer.append(first_backpointer)\n",
        "\n",
        "print('================')\n",
        "\n",
        "currbest = max(first_viterbi.keys(), key = lambda tag: first_viterbi[ tag ])\n",
        "print( \"Word\", \"'\" + sentence[0] + \"'\", \"current best two-tag sequence:\", first_backpointer[ currbest], currbest)\n",
        "# print( \"Word\", \"'\" + sentence[0] + \"'\", \"current best tag:\", currbest)\n",
        "\n",
        "print('================')\n",
        "\n",
        "##### Second-Timestep --TILL-- Last-Timestep\n",
        "for wordindex in range(1, len(sentence)):\n",
        "    ##### starting from the second word\n",
        "    this_viterbi = { }\n",
        "    this_backpointer = { }\n",
        "    prev_viterbi = viterbi[-1]\n",
        "    \n",
        "    for tag in distinct_tags:\n",
        "        # don't record anything for the START tag\n",
        "        if tag == \"START\": continue\n",
        "\n",
        "        # if this tag is X and the current word is w, then \n",
        "        # find the previous tag Y such that\n",
        "        # the best tag sequence that ends in X\n",
        "        # actually ends in Y X\n",
        "        # that is, the Y that maximizes\n",
        "        # prev_viterbi[ Y ] * P(X | Y) * P( w | X)\n",
        "        # The following command has the same notation\n",
        "        # that you saw in the sorted() command.\n",
        "        best_previous = max(prev_viterbi.keys(),\n",
        "                            key = lambda prevtag: \\\n",
        "            prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex]))\n",
        "\n",
        "        # Instead, we can also use the following longer code:\n",
        "        # best_previous = None\n",
        "        # best_prob = 0.0\n",
        "        # for prevtag in distinct_tags:\n",
        "        #    prob = prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex])\n",
        "        #    if prob > best_prob:\n",
        "        #        best_previous= prevtag\n",
        "        #        best_prob = prob\n",
        "        #\n",
        "        this_viterbi[ tag ] = prev_viterbi[ best_previous] * \\\n",
        "            cpd_tags[ best_previous ].prob(tag) * cpd_tagwords[ tag].prob(sentence[wordindex])\n",
        "        this_backpointer[ tag ] = best_previous\n",
        "\n",
        "    currbest = max(this_viterbi.keys(), key = lambda tag: this_viterbi[ tag ])\n",
        "    print( \"Word\", \"'\" + sentence[ wordindex] + \"'\", \"current best two-tag sequence:\", this_backpointer[ currbest], currbest)\n",
        "    # print( \"Word\", \"'\" + sentence[ wordindex] + \"'\", \"current best tag:\", currbest)\n",
        "    print('================')\n",
        "\n",
        "    # done with all tags in this iteration\n",
        "    # so store the current viterbi step\n",
        "    viterbi.append(this_viterbi)\n",
        "    backpointer.append(this_backpointer)\n",
        "\n",
        "\n",
        "# done with all words in the sentence.\n",
        "# now find the probability of each tag\n",
        "# to have \"END\" as the next tag,\n",
        "# and use that to find the overall best sequence\n",
        "prev_viterbi = viterbi[-1]\n",
        "best_previous = max(prev_viterbi.keys(),\n",
        "                    key = lambda prevtag: prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(\"END\"))\n",
        "\n",
        "prob_tagsequence = prev_viterbi[ best_previous ] * cpd_tags[ best_previous].prob(\"END\")\n",
        "\n",
        "# best tagsequence: we store this in reverse for now, will invert later\n",
        "best_tagsequence = [ \"END\", best_previous ]\n",
        "# invert the list of backpointers\n",
        "backpointer.reverse()\n",
        "\n",
        "# go backwards through the list of backpointers\n",
        "# (or in this case forward, because we have inverter the backpointer list)\n",
        "# in each case:\n",
        "# the following best tag is the one listed under\n",
        "# the backpointer for the current best tag\n",
        "current_best_tag = best_previous\n",
        "for bp in backpointer:\n",
        "    best_tagsequence.append(bp[current_best_tag])\n",
        "    current_best_tag = bp[current_best_tag]\n",
        "\n",
        "best_tagsequence.reverse()\n",
        "\n",
        "\n",
        "print('================')\n",
        "\n",
        "print( \"The sentence was:\", end = \" \")\n",
        "for w in sentence: print( w, end = \" \")\n",
        "print(\"\\n\")\n",
        "print( \"The best tag sequence is:\", end = \" \")\n",
        "for t in best_tagsequence: print(t, end = \" \")\n",
        "print(\"\\n\")\n",
        "print( \"The probability of the best tag sequence is:\", prob_tagsequence)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MD': 0.0, 'QL': 0.0, 'NR': 0.0, 'NI': 0.0, ')-': 0.0, '--': 0.0, 'EX': 0.0, 'WP': 0.0, 'NN': 0.0, '.': 0.0, 'RP': 0.0, 'RN': 0.0, 'PN': 0.0, 'IN': 0.0, 'WR': 0.0, 'VB': 0.0, 'END': 0.0, \"''\": 0.0, 'WD': 0.0, 'AP': 0.0, ',-': 0.0, \"'\": 0.0, 'FW': 0.0, 'WQ': 0.0, 'CD': 0.0, 'NP': 0.0, '``': 0.0, '.-': 0.0, 'TO': 0.0, '*': 0.0, 'PP': 0.0, ')': 0.0, 'UH': 0.0, 'AB': 0.0, 'DT': 0.0033218181276236437, ',': 0.0, 'HV': 0.0, ':-': 0.0, 'RB': 0.0, 'DO': 0.0, '(-': 0.0, ':': 0.0, 'CC': 0.0, 'JJ': 0.0, 'OD': 0.0, '(': 0.0, '*-': 0.0, 'BE': 0.0, 'CS': 0.0, 'AT': 0.0}\n",
            "{'MD': 'START', 'QL': 'START', 'NR': 'START', 'NI': 'START', ')-': 'START', '--': 'START', 'EX': 'START', 'WP': 'START', 'NN': 'START', '.': 'START', 'RP': 'START', 'RN': 'START', 'PN': 'START', 'IN': 'START', 'WR': 'START', 'VB': 'START', 'END': 'START', \"''\": 'START', 'WD': 'START', 'AP': 'START', ',-': 'START', \"'\": 'START', 'FW': 'START', 'WQ': 'START', 'CD': 'START', 'NP': 'START', '``': 'START', '.-': 'START', 'TO': 'START', '*': 'START', 'PP': 'START', ')': 'START', 'UH': 'START', 'AB': 'START', 'DT': 'START', ',': 'START', 'HV': 'START', ':-': 'START', 'RB': 'START', 'DO': 'START', '(-': 'START', ':': 'START', 'CC': 'START', 'JJ': 'START', 'OD': 'START', '(': 'START', '*-': 'START', 'BE': 'START', 'CS': 'START', 'AT': 'START'}\n",
            "================\n",
            "Word 'This' current best two-tag sequence: START DT\n",
            "================\n",
            "Word 'race' current best two-tag sequence: DT NN\n",
            "================\n",
            "Word 'is' current best two-tag sequence: NN BE\n",
            "================\n",
            "Word 'awesome' current best two-tag sequence: BE JJ\n",
            "================\n",
            "Word ',' current best two-tag sequence: JJ ,\n",
            "================\n",
            "Word 'I' current best two-tag sequence: , PP\n",
            "================\n",
            "Word 'want' current best two-tag sequence: PP VB\n",
            "================\n",
            "Word 'to' current best two-tag sequence: VB TO\n",
            "================\n",
            "Word 'race' current best two-tag sequence: IN NN\n",
            "================\n",
            "Word 'too' current best two-tag sequence: VB QL\n",
            "================\n",
            "================\n",
            "The sentence was: This race is awesome , I want to race too \n",
            "\n",
            "The best tag sequence is: START DT NN BE JJ , PP VB TO VB RB END \n",
            "\n",
            "The probability of the best tag sequence is: 3.9954320581626204e-33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P(END|QL) = 0 \n",
        "# P(END|RB) = 1"
      ],
      "metadata": {
        "id": "W_qusrjJrPhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('by default, the end statement is \\n -- i.e., next print will be in a new line')\n",
        "print('111next print')\n",
        "\n",
        "print('-=-=-=-=-=-=-=-=-')\n",
        "\n",
        "print('Now, we change the end statement to whilte space -- i.e., next print will be right after this print, following a white space', end = ' ')\n",
        "print('222new print')\n",
        "\n",
        "print('-=-=-=-=-=-=-=-=-')\n",
        "\n",
        "print('try something else', end = '@@@')\n",
        "print('333new print')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBhDgsqh2aq4",
        "outputId": "9d8fb46d-767c-487a-cf05-49c68914a066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "by default, the end statement is \n",
            " -- i.e., next print will be in a new line\n",
            "111next print\n",
            "-=-=-=-=-=-=-=-=-\n",
            "Now, we change the end statement to whilte space -- i.e., next print will be right after this print, following a white space 222new print\n",
            "-=-=-=-=-=-=-=-=-\n",
            "try something else@@@333new print\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLtm3qKYsDVZ"
      },
      "source": [
        "The code is implemented by [Katrin Erk](http://www.katrinerk.com/courses/python-worksheets/hidden-markov-models-for-pos-tagging-in-python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cY7cOjnUvMc"
      },
      "source": [
        "##  Train HMM Tagger with NLTK HMM Trainer\n",
        "\n",
        "The code above was a complete implementation of the details of an HMM. In this section, we will use an existing implementation in NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8akyRu6qvcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac53d9f-527a-4fbd-98a5-8adb00759863"
      },
      "source": [
        "# Pretagged training data\n",
        "brown_tagged_sents = brown.tagged_sents()\n",
        "\n",
        "print(brown_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftW_G61yqv_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bd9feb-78c4-4a66-8ddb-dde1734a1385"
      },
      "source": [
        "# Import HMM module\n",
        "from nltk.tag import hmm\n",
        "\n",
        "# Setup a trainer with default(None) values\n",
        "# And train with the data\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "trained_tagger = trainer.train_supervised(brown_tagged_sents)\n",
        "\n",
        "print (trained_tagger)\n",
        "# Prints the basic data about the tagger\n",
        "\n",
        "tokens = word_tokenize(\"This race is awesome, I want to race too\")\n",
        "print(trained_tagger.tag(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<HiddenMarkovModelTagger 472 states and 56057 output symbols>\n",
            "[('This', 'DT'), ('race', 'NN'), ('is', 'BEZ'), ('awesome', 'JJ'), (',', ','), ('I', 'PPSS'), ('want', 'VB'), ('to', 'TO'), ('race', 'VB'), ('too', 'QL')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxHS0Ji2p5X3"
      },
      "source": [
        "# Bi-LSTM based POS Tagger (Pytorch)\n",
        "\n",
        "In this example, we construct and train a PoS tagger using a Bi-LSTM model.\n",
        "\n",
        "![alt text](https://usydnlpgroup.files.wordpress.com/2020/03/bi-lstm_nton-e1586049916759.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1QJ5eXVztTO"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSHk_WHa_bfV"
      },
      "source": [
        "## Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYLogDRZH1cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a17495-1bbb-4739-abd7-446af96d70fa"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m4-XQjo6Qu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286554e1-d08a-4dc9-ccaa-5c78beb2291c"
      },
      "source": [
        "# Retrieve tagged sentences from treebank corpus\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        " \n",
        "print(tagged_sentences[0])\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))\n",
        "#tagged_words(): list of (str,str) tuple"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
            "Tagged sentences:  3914\n",
            "Tagged words: 100676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnE3URn56Qux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71376171-7e5a-4673-ce45-5a5478797696"
      },
      "source": [
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence = [v[0] for v in tagged_sentence]\n",
        "    tags = [v[1] for v in tagged_sentence]\n",
        "    sentences.append(np.array(sentence))\n",
        "    sentence_tags.append(np.array(tags))\n",
        " \n",
        "print(sentences[5])\n",
        "print(sentence_tags[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lorillard' 'Inc.' ',' 'the' 'unit' 'of' 'New' 'York-based' 'Loews'\n",
            " 'Corp.' 'that' '*T*-2' 'makes' 'Kent' 'cigarettes' ',' 'stopped' 'using'\n",
            " 'crocidolite' 'in' 'its' 'Micronite' 'cigarette' 'filters' 'in' '1956'\n",
            " '.']\n",
            "['NNP' 'NNP' ',' 'DT' 'NN' 'IN' 'JJ' 'JJ' 'NNP' 'NNP' 'WDT' '-NONE-' 'VBZ'\n",
            " 'NNP' 'NNS' ',' 'VBD' 'VBG' 'NN' 'IN' 'PRP$' 'NN' 'NN' 'NNS' 'IN' 'CD'\n",
            " '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn34twJZ6Qut"
      },
      "source": [
        "(train_sentences, \n",
        " test_sentences, \n",
        " train_tags, \n",
        " test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKCc8BbR_l87"
      },
      "source": [
        "### Making vocab with special tokens\n",
        "\n",
        "*PAD: Padding*\n",
        "\n",
        "*OOV: Out Of Vocabulary*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY1FlDIo6Quo"
      },
      "source": [
        "words, tags = set([]), set([])\n",
        " \n",
        "for s in train_sentences:\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        "\n",
        "for ts in train_tags:\n",
        "    for t in ts:\n",
        "        tags.add(t)\n",
        "\n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        "\n",
        "tag2index = {t: i + 2 for i, t in enumerate(list(tags))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to tag padding\n",
        "tag2index['-OOV-'] = 1  # The special value used to tag OOVs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_T_YTL6Qug"
      },
      "source": [
        "def encode_sentences(sentences):\n",
        "    res = []\n",
        "    for sent in sentences:\n",
        "        temp = [word2index[word.lower()] if word.lower() in word2index else word2index['-OOV-'] for word in sent]\n",
        "        res.append(temp)\n",
        "    return res\n",
        "\n",
        "train_sentences_encoded = encode_sentences(train_sentences)\n",
        "test_sentences_encoded = encode_sentences(test_sentences)\n",
        "\n",
        "\n",
        "train_tags_y, test_tags_y = [], []\n",
        "\n",
        "def tag_to_index(tags_list):\n",
        "    res = []\n",
        "    for tags in tags_list:\n",
        "        temp = [tag2index[tag] if tag in tag2index else tag2index['-OOV-'] for tag in tags]\n",
        "        res.append(temp)\n",
        "    return res\n",
        "\n",
        "train_tags_y = tag_to_index(train_tags)\n",
        "test_tags_y = tag_to_index(test_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eb-SNMWFdxG"
      },
      "source": [
        "### Padding\n",
        "\n",
        "Not all of our sentences are the same length, but d\n",
        "During training it is easier to work with sequences that are the same length, but our sentences vary in length. We solve this by adding padding (adding \"-PAD-\" enough times to make the sentences a certain length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9US1y_a6QuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724df6ee-2176-4bb3-c061-528d5aa184a3"
      },
      "source": [
        "# Pad to max_length\n",
        "max_length = len(max(train_sentences_encoded, key=len))\n",
        "print(max_length) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d5WoxwabuYC"
      },
      "source": [
        "def pad_sequence(seq_list, max_length, index_dict):\n",
        "    res = []\n",
        "    for seq in seq_list:\n",
        "        temp = seq[:]\n",
        "        if len(seq)>max_length:\n",
        "            res.append(temp[:max_length])\n",
        "        else:\n",
        "            temp += [index_dict['-PAD-']] * (max_length - len(seq))\n",
        "            res.append(temp)\n",
        "    return np.array(res)\n",
        "\n",
        "train_sentences_encoded_pad = pad_sequence(train_sentences_encoded, max_length, word2index)\n",
        "test_sentences_encoded_pad = pad_sequence(test_sentences_encoded, max_length, word2index)\n",
        "train_tags_y_pad = pad_sequence(train_tags_y, max_length, tag2index)\n",
        "test_tags_y_pad = pad_sequence(test_tags_y, max_length, tag2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJE3qT2Vi0hL"
      },
      "source": [
        "### Build Dataset and Dataloader for training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLmjfFnVi3vp"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "#More detailed info about the TensorDataset, https://pytorch.org/docs/1.1.0/_modules/torch/utils/data/dataset.html#TensorDataset\n",
        "train_data = TensorDataset(torch.from_numpy(train_sentences_encoded_pad), torch.from_numpy(train_tags_y_pad))\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "#More detailed info about the dataLoader, https://pytorch.org/docs/1.1.0/_modules/torch/utils/data/dataloader.html\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True) \n",
        "# shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjTDYN3sFtet"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U7kYumQjagT"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)  \n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        tag_space = self.hidden2tag(lstm_out)   \n",
        "        return tag_space\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2index), len(tag2index)).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, the cell below can take 30+ minutes if you do not have GPU.\n",
        "\n",
        "For the purpose of this lab, running for 2 epochs (which takes < 5 minutes) is sufficient if you don't want to wait and can't get access to a GPU."
      ],
      "metadata": {
        "id": "s_V-MCHgcYXJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d29F38by01H",
        "outputId": "f56303ba-5a53-49ab-fc6f-e4cdc4769fe7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "number_epochs = 20\n",
        "\n",
        "for epoch in range(number_epochs):  \n",
        "    loss_now = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for sentence,targets in train_loader:\n",
        "        sentence = sentence.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        temp_batch_size = sentence.shape[0]\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()               \n",
        "        tag_space = model(sentence)\n",
        "        loss = loss_function(tag_space.view(-1, tag_space.shape[-1]), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_now += loss.item() * temp_batch_size\n",
        "        predicted = torch.argmax(tag_space, -1)\n",
        "        # Note: The training accuracy here is calculated with \"PAD\", which will result in a relative higher accuracy.\n",
        "        correct += accuracy_score(predicted.view(-1).cpu().numpy(),targets.view(-1).cpu().numpy())*temp_batch_size\n",
        "\n",
        "    print('Epoch: %d, training loss: %.4f, training accuracy: %.2f%%'%(epoch+1,loss_now/len(train_data),100*correct/len(train_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, training loss: 0.7572, training accuracy: 87.25%\n",
            "Epoch: 2, training loss: 0.3024, training accuracy: 92.91%\n",
            "Epoch: 3, training loss: 0.2378, training accuracy: 94.25%\n",
            "Epoch: 4, training loss: 0.1994, training accuracy: 94.94%\n",
            "Epoch: 5, training loss: 0.1676, training accuracy: 95.60%\n",
            "Epoch: 6, training loss: 0.1409, training accuracy: 96.31%\n",
            "Epoch: 7, training loss: 0.1193, training accuracy: 96.82%\n",
            "Epoch: 8, training loss: 0.1020, training accuracy: 97.27%\n",
            "Epoch: 9, training loss: 0.0878, training accuracy: 97.66%\n",
            "Epoch: 10, training loss: 0.0761, training accuracy: 97.95%\n",
            "Epoch: 11, training loss: 0.0664, training accuracy: 98.21%\n",
            "Epoch: 12, training loss: 0.0585, training accuracy: 98.42%\n",
            "Epoch: 13, training loss: 0.0515, training accuracy: 98.62%\n",
            "Epoch: 14, training loss: 0.0456, training accuracy: 98.79%\n",
            "Epoch: 15, training loss: 0.0404, training accuracy: 98.94%\n",
            "Epoch: 16, training loss: 0.0360, training accuracy: 99.06%\n",
            "Epoch: 17, training loss: 0.0321, training accuracy: 99.17%\n",
            "Epoch: 18, training loss: 0.0287, training accuracy: 99.26%\n",
            "Epoch: 19, training loss: 0.0257, training accuracy: 99.34%\n",
            "Epoch: 20, training loss: 0.0232, training accuracy: 99.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w8nzr_Kq_oA"
      },
      "source": [
        "## Test with the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw0HMLN7ou6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67913b5a-e324-49eb-92e3-eae33b6ca78e"
      },
      "source": [
        "model.eval()\n",
        "sentence = torch.from_numpy(test_sentences_encoded_pad).to(device)\n",
        "tag_space = model(sentence)\n",
        "predicted = torch.argmax(tag_space, -1)\n",
        "predicted = predicted.cpu().numpy()\n",
        "\n",
        "# cut off the PAD part\n",
        "test_len_list = [len(s) for s in test_sentences_encoded]\n",
        "actual_predicted_list= []\n",
        "for i in range(predicted.shape[0]):\n",
        "    actual_predicted_list+=list(predicted[i])[:test_len_list[i]]\n",
        "\n",
        "# get actual tag list\n",
        "actual_tags = sum(test_tags_y, [])\n",
        "\n",
        "print('Test Accuracy: %.2f%%'%(accuracy_score(actual_predicted_list,actual_tags)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 88.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extension: Saving Data"
      ],
      "metadata": {
        "id": "WJsaPoN3ER_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample code for saving data to files."
      ],
      "metadata": {
        "id": "GPJaQaAZEd5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV file\n",
        "\n",
        "Useful for saving tables of data in a way that you can look at (e.g., with a text editor) or read into a spreadsheet application."
      ],
      "metadata": {
        "id": "DciCOXqXAnPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = ['this is a cat', 'today is a sunny day']\n",
        "df = pd.DataFrame(data,columns=['data'])\n",
        "\n",
        "# Save data to csv file\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
        "df.to_csv('save_as_csv.csv')"
      ],
      "metadata": {
        "id": "UAiyyYVNAhF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved data\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv\n",
        "df = pd.read_csv('save_as_csv.csv')\n",
        "\n",
        "# data.head() # Uncomment to check how the data look like\n",
        "\n",
        "data = df['data'].tolist()\n",
        "data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcN6HS7AjY8",
        "outputId": "a429b722-3813-4470-ad24-97ea3aec3888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a cat', 'today is a sunny day']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON file\n",
        "\n",
        "Convenient if you want to be able to look at the output (e.g., with a text editor) or read it into a different program, even using a different langauge."
      ],
      "metadata": {
        "id": "Hoc3MygGAqcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data = [['this','is','a','cat'],['today','is','a','sunny','day']]\n",
        "data_dict = {'data': data}\n",
        "\n",
        "# Save data to json file\n",
        "with open('save_as_json.json','w') as f:\n",
        "  json.dump(data_dict,f)"
      ],
      "metadata": {
        "id": "EMVl-3xAAuxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from json file\n",
        "with open('save_as_json.json','r') as f:\n",
        "  data=json.load(f)\n",
        "data['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaBMW0UkAvHS",
        "outputId": "7f6164e5-6c01-4842-be64-f9139e02b93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['this', 'is', 'a', 'cat'], ['today', 'is', 'a', 'sunny', 'day']]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pickle (pkl) file\n",
        "\n",
        "Convenient for Python objects that you plan to reopen in Python later."
      ],
      "metadata": {
        "id": "Enln0CrCAzg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "data = [['this','is','a','cat'],['today','is','a','sunny','day']]\n",
        "data_dict = {'data': data}\n",
        "\n",
        "# Save data to pkl file\n",
        "with open('save_as_pkl.pkl','wb') as f:\n",
        "  pickle.dump(data_dict,f)"
      ],
      "metadata": {
        "id": "ay4J-W-DA3iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from pkl file\n",
        "with open('save_as_pkl.pkl','rb') as f:\n",
        "  data=pickle.load(f)\n",
        "data['data']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdhuwFPtA4Gj",
        "outputId": "ec63aa5b-529c-4161-cc18-17917e652299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['this', 'is', 'a', 'cat'], ['today', 'is', 'a', 'sunny', 'day']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save files from colab to your google drive\n",
        "\n",
        "The example below shows how to mount your Google Drive on z runtime using an authorization code, and how to write and read files. Once executed, you will be able to see the new file (`foo.txt`) at [https://drive.google.com/](https://drive.google.com/)."
      ],
      "metadata": {
        "id": "ifLwR1FuBUov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/foo.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoxBD9WNBe2D",
        "outputId": "9b385f22-def0-43db-eff3-8dba9fcc3626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "Hello Google Drive!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the saved data file from colab to your google drive\n",
        "# save_as_pkl.pkl is generated using the sample code from the section above\n",
        "!cp save_as_pkl.pkl /gdrive/My\\ Drive"
      ],
      "metadata": {
        "id": "V5I99-ZWBgMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After you copy or move your saved data file to your google drive\n",
        "# you can load it directly from your google drive later \n",
        "with open('/gdrive/My Drive/save_as_pkl.pkl','rb') as f:\n",
        "  data=pickle.load(f)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnRorSrGBh2c",
        "outputId": "a8173b4c-3a19-42fb-c62c-e587f2b8c0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': [['this', 'is', 'a', 'cat'], ['today', 'is', 'a', 'sunny', 'day']]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}